# Plugins
import plugins.fec
import plugins.vfake
import plugins.rownum

# Function defs
import re
import os
import functools
import tldextract
import emoji
from subprocess import call
from dateutil import tz
from dateutil import parser
from geopy.geocoders import Nominatim

to_zone = tz.tzlocal()

geolocator = Nominatim(user_agent="SIO")
geocode = functools.lru_cache(maxsize=65535)(
    functools.partial(geolocator.geocode, timeout=5)
)

# Convert to a more sensible datetime
def time(column):
    return parser.parse(column)


# Same but local time
def ltime(column):
    return parser.parse(column).astimezone(to_zone)


# Strip HTML tags
def nohtml(column):
    tag_re = re.compile(r"(<!--.*?-->|<[^>]*>)")
    return tag_re.sub("", column)


def noemoji(column):
    allchars = [str for str in column]
    emoji_list = [c for c in allchars if c in emoji.UNICODE_EMOJI]
    clean_text = " ".join(
        [str for str in column.split() if not any(i in str for i in emoji_list)]
    )

    return clean_text


# Do a cached geocode lookup via Nominatim
def coords(column):
    location = geocode(column)
    return str(location.latitude) + " " + str(location.longitude)


# Take a URL to an image and display it on the terminal
def img(url):
    call("kitty +kitten icat --detection-timeout 1 --silent " + url, shell=True)


def hashtags(column):
    return [hashtag["text"] for hashtag in column["hashtags"]]


def mentions(column):
    return [name["screen_name"] for name in column["user_mentions"]]


# Walk Twitter url arrays to extract the most verbose version of the url
def urls(column):
    results = []
    for url in column["urls"]:
        if "unwound_url" in url:
            results.append(url["unwound_url"])
        elif url.get("expanded_url"):
            results.append(url["expanded_url"])
        elif url.get("url"):
            results.append(url["url"])

    return results


def domains(column):
    return tldextract.extract(column).registered_domain


# These re- functions are for plain text fields where we don't have
# these as separate metadata/columns
def rementions(column):
    return re.findall(r"\B@\w\w+", column)


def reurls(column):
    regex = r"(?i)\b((?:https?://|www\d{0,3}[.]|[a-z0-9.\-]+[.][a-z]{2,4}/)(?:[^\s()<>]+|\(([^\s()<>]+|(\([^\s()<>]+\)))*\))+(?:\(([^\s()<>]+|(\([^\s()<>]+\)))*\)|[^\s`!()\[\]{};:'\".,<>?«»“”‘’]))"
    url = re.findall(regex, column)
    return [x[0] for x in url]


def rehashtags(column):
    return re.findall(r"\B#\w\w+", column)


def semis(column):
    return column.split(";")

# Convert abbreviated numbers like 1.1k to actual numbers
def unk(x):
    if x.isdigit():
        return int(x)
    else:
        if len(x) > 1:
            y = float(x[:-1]) * 1000
    return int(y)


# Options
options.disp_column_sep = "│"
options.disp_keycol_sep = "║"
options.use_default_colors = True
# This is is very specific to my workflow, you want to use pbcopy
options.clipboard_copy_cmd = "vdcopy"
options.clipboard_paste_cmd = "pbpaste"
options.clean_names = True
options.numeric_binning = False
options.disp_ambig_width = 2
options.color_key_col = 110
options.color_note_type = 8
save_filetype = "csv"

# Keybindings
bindkey("0", "go-leftmost")
bindkey("4", "go-rightmost")

# Whether you want binning is pretty context-specific, so these let
# you switch modes
Sheet.addCommand("b", "nobinning", "options.numeric_binning=False")
Sheet.addCommand("B", "binning", "options.numeric_binning=True")

# I keep needing to switch date formats, so make z@ do a "zoom" and show date+time
Sheet.addCommand(
    "@", "shortdate", 'options.disp_date_fmt = "%Y-%m-%d"; cursorCol.type=date'
)
Sheet.addCommand(
    "z@", "longdate", 'options.disp_date_fmt = "%Y-%m-%d %H:%M"; cursorCol.type=date'
)

# See if I can make GitHub highlight properly
/* vim: syntax=python */
